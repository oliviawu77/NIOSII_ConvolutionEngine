"# NIOSII_ConvolutionEngine" 

卷積神經網路 (CNN) 為時下熱門應用。然而，其中大量的卷積運算，造成了效能瓶頸。目前已經有研究指出卷積層的運算時間在整個卷積神經網路中佔了高達 90 % 以上。其中，記憶體存取的成本，成為了影響效能的關鍵角色。由於存取外部記憶體的成本非常昂貴，因此如果處理器必須頻繁地從外部記憶體存取資料進來運算，效能勢必會受限於昂貴的記憶體存取。反之，若能讓資料在內部記憶體被多次重複使用，而不用每次都去外部記憶體存取資料，效能就可以有明顯提升。因此資料如何在整個系統中的記憶體階層中流動，會大大地影響整體運算效能。為了優化卷積運算的效能，本研究試圖從減少外部記憶體存取的方式，來去降低外部記憶體存取時間。

本研究提出了 CALTP (Convolution Accelerator with Loop Transformation and Parallelization) 的方法，從軟體演算法和硬體的角度來去切入，優化卷積運算的時間。從軟體演算法方面，使用了迴圈區塊化 (Loop Tiling) 和迴圈平行化 (Loop Parallelization) 來去轉換二維卷積運算的迴圈結構，提升資料在內部記憶體被重複使用的機會。並且迴圈區塊化的參數會搭配內部記憶體大小來調整，而迴圈平行化的參數則會搭配我們所設計的卷積加速器中擺放的運算單元數量來去調整。從硬體方面，我們設計了一個卷積加速器，作為是 RISC-V CPU 旁外掛的協同處理器 (co-processor) ，專門處理卷積相關的指令。本卷積加速器主要是基於 Systolic Array 的架構來去設計，讓資料可以在多個做卷積運算的運算單元中流動，以達到資料重複使用的目的。

本研究針對了 VGG-16 和 VGG-SA 兩個神經網路架構做實驗，並且比較三種方法 GEMM、GEMM_TILE 和 CALTP 間的效能差異。除此之外，本實驗也在每個方法下調整不同迴圈區塊化的參數，來去比較提升迴圈區塊化的參數後是否能讓效能提升。實驗結果顯示，調大迴圈區塊化的參數後，CALTP 比起 GEMM，在 VGG-16 的實驗中可以達到至少 2.44 倍的加速，而在 VGG-SA 的實驗中則是可以達到至少 1.97 倍的加速。
